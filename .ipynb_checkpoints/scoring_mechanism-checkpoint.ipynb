{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Mechanism to Quantify Different Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/madhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, string\n",
    "from scipy import spatial\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('punkt') \n",
    "\n",
    "embeddings = {}\n",
    "with open(\"data/AffectVec-v2.0-w2v.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        word = line.split()[0]\n",
    "        embeddings[word] = np.asarray(line.split()[1:], \"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Developing LIWC-Inspired Scoring Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(word):\n",
    "    return sorted(embeddings.keys(), key=lambda w: spatial.distance.euclidean(embeddings[w], word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def compute_similarity(word1, word2):\n",
    "    token1, token2 = nlp(word1), nlp(word2)\n",
    "    return token1.similarity(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('liwc.csv', names=[\"Category\", \"Abbrev\", \"Examples\", \"5 Nearest Neighbors\", \"All Neighbors\"])\n",
    "\n",
    "for ind in df.index:\n",
    "    value = df[\"Examples\"][ind]\n",
    "    val = list(value.split(\",\"))\n",
    "    df['Examples'][ind] = val\n",
    "\n",
    "for ind in df.index:\n",
    "    examples = df[\"Examples\"][ind]\n",
    "    neighbors = []\n",
    "    for example in examples:\n",
    "        ex_neigh = []\n",
    "        try:\n",
    "            nn = nearest_neighbors(embeddings[example.lower().replace(\"'\", \"\")])[1:6]\n",
    "            for n in nn:\n",
    "                ex_neigh.append(n)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        neighbors.append(ex_neigh)      \n",
    "    df['5 Nearest Neighbors'][ind] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    examples = df[\"Examples\"][ind]\n",
    "    neighbors = []\n",
    "    for example in examples:\n",
    "        ex_neigh = []\n",
    "        try:\n",
    "            nn = nearest_neighbors(embeddings[example.lower().replace(\"'\", \"\")])\n",
    "            for n in nn:\n",
    "                ex_neigh.append(n)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        neighbors.append(ex_neigh)      \n",
    "    df['All Neighbors'][ind] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Examples</th>\n",
       "      <th>5 Nearest Neighbors</th>\n",
       "      <th>All Neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total function words</td>\n",
       "      <td>funct</td>\n",
       "      <td>[it, to, no, very]</td>\n",
       "      <td>[[ey, ec, him, ti, es], [per, at, pour, of, au...</td>\n",
       "      <td>[[it, ey, ec, him, ti, es, did, both, could, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total pronouns</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>[I, them, itself]</td>\n",
       "      <td>[[li, je, ich, j, me], [thier, ones, where, al...</td>\n",
       "      <td>[[i, li, je, ich, j, me, es, ti, te, jag, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personal pronouns</td>\n",
       "      <td>ppron</td>\n",
       "      <td>[I, them, her]</td>\n",
       "      <td>[[li, je, ich, j, me], [thier, ones, where, al...</td>\n",
       "      <td>[[i, li, je, ich, j, me, es, ti, te, jag, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First pers singular</td>\n",
       "      <td>i</td>\n",
       "      <td>[I, me, mine]</td>\n",
       "      <td>[[li, je, ich, j, me], [could, am, did, i, ai]...</td>\n",
       "      <td>[[i, li, je, ich, j, me, es, ti, te, jag, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First pers plural</td>\n",
       "      <td>we</td>\n",
       "      <td>[we, us, our]</td>\n",
       "      <td>[[ours, ourselves, nous, our, notre], [america...</td>\n",
       "      <td>[[we, ours, ourselves, nous, our, notre, mysel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Swear words</td>\n",
       "      <td>swear</td>\n",
       "      <td>[fuck, damn, shit]</td>\n",
       "      <td>[[fucking, cunt, damn, goddam, fucker], [godda...</td>\n",
       "      <td>[[fuck, fucking, cunt, damn, goddam, fucker, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Netspeak</td>\n",
       "      <td>netspeak</td>\n",
       "      <td>[btw, lol, thx]</td>\n",
       "      <td>[[yah, yup, atleast, yea, yep], [jk, lola, iz,...</td>\n",
       "      <td>[[btw, yah, yup, atleast, yea, yep, thats, vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Assent</td>\n",
       "      <td>assent</td>\n",
       "      <td>[agree, OK, yes]</td>\n",
       "      <td>[[agreeing, approve, accord, accept, approved]...</td>\n",
       "      <td>[[agree, agreeing, approve, accord, accept, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Nonfluencies</td>\n",
       "      <td>nonflu</td>\n",
       "      <td>[er, hm, umm]</td>\n",
       "      <td>[[sos, roe, re, uh, hmm], [hmm, um, oum, huh, ...</td>\n",
       "      <td>[[er, sos, roe, re, uh, hmm, eh, mayday, wat, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Fillers</td>\n",
       "      <td>filler</td>\n",
       "      <td>[Imean, youknow]</td>\n",
       "      <td>[[comeon, wwould, meybe, pshh, somee], [youthi...</td>\n",
       "      <td>[[imean, comeon, wwould, meybe, pshh, somee, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Category     Abbrev            Examples  \\\n",
       "0   Total function words      funct  [it, to, no, very]   \n",
       "1         Total pronouns    pronoun   [I, them, itself]   \n",
       "2      Personal pronouns      ppron      [I, them, her]   \n",
       "3    First pers singular          i       [I, me, mine]   \n",
       "4      First pers plural         we       [we, us, our]   \n",
       "..                   ...        ...                 ...   \n",
       "66           Swear words      swear  [fuck, damn, shit]   \n",
       "67              Netspeak   netspeak     [btw, lol, thx]   \n",
       "68                Assent     assent    [agree, OK, yes]   \n",
       "69         Nonfluencies      nonflu       [er, hm, umm]   \n",
       "70               Fillers     filler    [Imean, youknow]   \n",
       "\n",
       "                                  5 Nearest Neighbors  \\\n",
       "0   [[ey, ec, him, ti, es], [per, at, pour, of, au...   \n",
       "1   [[li, je, ich, j, me], [thier, ones, where, al...   \n",
       "2   [[li, je, ich, j, me], [thier, ones, where, al...   \n",
       "3   [[li, je, ich, j, me], [could, am, did, i, ai]...   \n",
       "4   [[ours, ourselves, nous, our, notre], [america...   \n",
       "..                                                ...   \n",
       "66  [[fucking, cunt, damn, goddam, fucker], [godda...   \n",
       "67  [[yah, yup, atleast, yea, yep], [jk, lola, iz,...   \n",
       "68  [[agreeing, approve, accord, accept, approved]...   \n",
       "69  [[sos, roe, re, uh, hmm], [hmm, um, oum, huh, ...   \n",
       "70  [[comeon, wwould, meybe, pshh, somee], [youthi...   \n",
       "\n",
       "                                        All Neighbors  \n",
       "0   [[it, ey, ec, him, ti, es, did, both, could, t...  \n",
       "1   [[i, li, je, ich, j, me, es, ti, te, jag, my, ...  \n",
       "2   [[i, li, je, ich, j, me, es, ti, te, jag, my, ...  \n",
       "3   [[i, li, je, ich, j, me, es, ti, te, jag, my, ...  \n",
       "4   [[we, ours, ourselves, nous, our, notre, mysel...  \n",
       "..                                                ...  \n",
       "66  [[fuck, fucking, cunt, damn, goddam, fucker, b...  \n",
       "67  [[btw, yah, yup, atleast, yea, yep, thats, vid...  \n",
       "68  [[agree, agreeing, approve, accord, accept, ap...  \n",
       "69  [[er, sos, roe, re, uh, hmm, eh, mayday, wat, ...  \n",
       "70  [[imean, comeon, wwould, meybe, pshh, somee, o...  \n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('liwc_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crappy', 'crappi']\n",
      "['worry', 'worri']\n",
      "['daught', 'daughter']\n",
      "['leav', 'leaf']\n",
      "['swim']\n",
      "['com', 'come']\n",
      "['strawberry', 'strawberri']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def word_stem(original):\n",
    "    lancaster = st.stem(original)\n",
    "    wordnet = wnl.lemmatize(original)\n",
    "    snow = sno.stem(original)\n",
    "    port = porter.stem(original)\n",
    "    options = [lancaster, wordnet, snow, port]\n",
    "    if original in options:\n",
    "        options.remove(original)\n",
    "    res = [] \n",
    "    [res.append(x) for x in options if x not in res] \n",
    "    return res\n",
    "\n",
    "wordlist = [\"crappy\", \"worrying\", \"daughters\", \"leaves\", \"swimming\", \"coming\", \"strawberries\"]\n",
    "\n",
    "for word in wordlist:\n",
    "    print(word_stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "    \n",
    "def find_category(word):\n",
    "    category = []\n",
    "    for ind in df.index:\n",
    "        if category == []:\n",
    "            if word in df[\"Examples\"][ind]:\n",
    "                category.append(ind)\n",
    "            else:\n",
    "                stemmed = word_stem(word)\n",
    "                for item in stemmed:\n",
    "                    if item in df[\"Examples\"][ind]:\n",
    "                        category.append(ind)\n",
    "    if category == []: \n",
    "        for ind in df.index:\n",
    "            if category == []:\n",
    "                for i in range(len(df[\"5 Nearest Neighbors\"][ind])):\n",
    "                    if word in df[\"5 Nearest Neighbors\"][ind][i]:\n",
    "                        category.append(ind) \n",
    "                    else:\n",
    "                        stemmed = word_stem(word)\n",
    "                        for item in stemmed:\n",
    "                            if item in df[\"5 Nearest Neighbors\"][ind][i]:\n",
    "                                category.append(ind)\n",
    "\n",
    "    if category == []: \n",
    "        for ind in df.index:\n",
    "            if category == []:\n",
    "                for i in range(len(df[\"All Neighbors\"][ind])):\n",
    "                    if category == []:\n",
    "                        if word in df[\"All Neighbors\"][ind][i]:\n",
    "                            category.append(ind) \n",
    "                        else:\n",
    "                            stemmed = word_stem(word)\n",
    "                            for item in stemmed:\n",
    "                                if item in df[\"All Neighbors\"][ind][i]:\n",
    "                                    category.append(ind)\n",
    "    if category == []:\n",
    "        category.append(0)\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_score(word_score):\n",
    "    word, index = word_score[0], word_score[1]\n",
    "    neigh = [item for sublist in df[\"5 Nearest Neighbors\"][index] for item in sublist]\n",
    "    examples = df[\"Examples\"][index] + neigh\n",
    "    if word in examples:\n",
    "        return 1\n",
    "    \n",
    "    max_score = 0\n",
    "    for ex in examples:\n",
    "        score = compute_similarity(word, ex)\n",
    "        if score > max_score:\n",
    "            max_score = score   \n",
    "    return max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_code(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence.lower())\n",
    "\n",
    "    word_categories = []\n",
    "    for word in sentence.split(' '):\n",
    "        belongsto = [word, find_category(word)[0]]\n",
    "        word_categories.append(belongsto)\n",
    "\n",
    "    category_scores = []\n",
    "    for i in word_categories:\n",
    "        sco = maximum_score(i)\n",
    "        if sco is not 99:\n",
    "            category_scores.append((i[1],sco))\n",
    "    \n",
    "    cat_sco = {}\n",
    "    result = []\n",
    "    for a, b in category_scores: \n",
    "        cat_sco.setdefault(a, []).append(b)  \n",
    "    for key, value in cat_sco.items(): \n",
    "        result.append((df[\"Category\"][key], sum(value)/len(category_scores))) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Total function words', 0.39812606986139715), ('First pers singular', 0.0625), ('Insight', 0.0625), ('Discrepancy', 0.0625), ('Articles', 0.0625), ('Conjunctions', 0.0625), ('Present focus', 0.0625)]\n"
     ]
    }
   ],
   "source": [
    "print(scoring_code(\"Very loud! I didn't think noise would ever be an issue but this is WAY louder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scoring 20 Amazon Reviews (10 1-Star and 10 5-Star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "ap1 ='We bought a brand new set of AirPods for 159. After using them for a week, I was listening to them and the right air pod went dead. I figured, maybe I just need to charge them. So when I got home I charged them, and the next day I went to use them again and the right air bud was still dead. So I did some research, tried to reset them, and then I couldnt reconnect them to my phone at all. Once I contacted Apple, they tried to give us the run around. They wanted us to let them fully die, which makes sense, so we did that. Then, when they still didnt work we wanted to exchange the faulty pair for a new set (BECAUSE WE PAID 159 DOLLARS AND ONLY USED THEM FOR A WEEK). Keep in mind, they were taken care of, not dropped, no water damage, they were expensive so they were treated delicately. Apple wanted a 180 deposit to get a new set, which is MORE THAN WHAT I ORIGINALLY PAID FOR. I decided to contact Amazon, and they suggested contacting Apple, but once I explained what was going, on Amazon offered to make things right and send out a replacement. Never had an issue with Amazon customer service, but Apple was extremely disappointing. I wont purchase these again.' \n",
    "ap2 = \"These AirPods are amazing they automatically play audio as soon as you put them in your ears and pause when you take them out. A simple double-tap during music listening will skip forward. To adjust the volume, change the song, make a call, or even get directions, just say Hey Siri to activate your favorite personal assistant. Plus, when youre on a call or talking to Siri, an additional accelerometer works with dual beamforming microphones to filter out background noise and ensure that your voice is transmitted with clarity and consistency. Additionally, they deliver five hours of listening time on a single charge, and theyre made to keep up with you thanks to a charging case that holds multiple additional charges for more than 24 hours of listening time. Just 15 minutes in the case gives you three hours of listening to time or up to two hours of talk time. I would highly recommend it to anyone looking to buy\"\n",
    "                  \n",
    "airpod_reviews = {'Product Reviewed': [\"Apple AirPods with Charging Case\", \"Apple AirPods with Charging Case\"],\n",
    "        'Sentence':[ap1, ap2], \n",
    "                  'Score':[scoring_code(ap1),scoring_code(ap2)]} \n",
    "   \n",
    "amazon_df = pd.DataFrame(airpod_reviews) \n",
    "\n",
    "blender1 = \"Very loud! I didn't think noise would ever be an issue but this is WAY louder than any blender Iâ€™ve owned in the past. The base is also very heavy and suctions to surfaces, so not ideal if you are constantly getting out/putting away (I personally do not like appliances sitting out on the counter when not in use). The smaller sized cups are so tall with just a tiny blade at the bottom, I can never get it to blend my ingredients - so basically they are useless. Sadly will be throwing this away and getting something else ASAP.\"\n",
    "blender2 = \"This is my third NB purchase and by far the most impressive product. The first two were 600 and 900 watts, which lasted about 3 years each when the motors burned out. I assume this was because of filling too close to the lines. This model has several improvements, including multiple speeds and functions, an actual blender, plus the 32 and 24 oz cups for smoothies; it is quieter and more high tech. The old style cup had rubber gaskets that were inset and fouled if not very carefully cleaned by removing them. The new cups have eliminated this problem. I expect to enjoy this NB more and for it to last longer than my first two.\"\n",
    "\n",
    "blender_reviews = [pd.Series([\"NutriBullet\", blender1, scoring_code(blender1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"NutriBullet\", blender2, scoring_code(blender2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(blender_reviews, ignore_index=True)\n",
    "\n",
    "bar1 = \"Tastes terrible and super sweet\"\n",
    "bar2 = \"shipped fast, product was in perfect order and shape. flavor GREAT price GOOD Popular with work out crew lots of flavors the guys loved flavors the guys loved Low sugar high protein\"\n",
    "\n",
    "bar_reviews = [pd.Series([\"CLIF BAR - Energy Bars\", bar1, scoring_code(bar1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"CLIF BAR - Energy Bars\", bar2, scoring_code(bar2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(bar_reviews, ignore_index=True)\n",
    "\n",
    "tp1 = \"Rolls are way too narrow and not worth the cost. Basucally Family Mega...translates into better have child size hands. Never buy again!!\"\n",
    "tp2 = \"I've been using this toilet paper for several years now. I order a case each month at the much-cheaper Amazon Subscribe & Save price. This paper is thick, very absorbent, doesnt contain any scents or dyed that cause any irritation for me or my family. One case of 18 huge rolls lasts our family with 2 bathrooms for 1 whole month. I've tried most all other brands and this one lasts the longest of any of them. I pray that Amazon never stops carrying this product.\"\n",
    "\n",
    "tp_reviews = [pd.Series([\"Charmin Ultra Soft Cushiony Touch Toilet Paper\", tp1, scoring_code(tp1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"Charmin Ultra Soft Cushiony Touch Toilet Paper\", tp2, scoring_code(tp2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(tp_reviews, ignore_index=True)\n",
    "\n",
    "shampoo1 = \"Never been a fan of pantene but read some good reviews and decided to try this shampoo and conditioner set especially because it said it was sulfate free... At first it made my hair shiny that was after the first wash.. Then After the second wash my hair started to fall out in chunks and It makes me mad cause I was already growing it out I was left with my hair being all thinned out and i lost about 2 inches in length..please do not buy this shampoo and conditioner its crap! There are better options out there and cheaper!\"\n",
    "shampoo2 = \"My fav, go-to shampoo and conditioner for years. I occasionally add another brand but always go back to Pantene. Products 4x the price donâ€™t work as well! Iâ€™ve used Purology, Tea Tree Paul Mitchell, Aveda, etc, always go back to this!\"\n",
    "\n",
    "shampoo_reviews = [pd.Series([\"Pantene Moisturizing Shampoo and Conditioner\", shampoo1, scoring_code(shampoo1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"Pantene Moisturizing Shampoo and Conditioner\", shampoo2, scoring_code(shampoo2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(shampoo_reviews, ignore_index=True)\n",
    "\n",
    "paint1 = \"Half of the colors are dry. I did not realized it after the return policy expired. Very disappointed.\"\n",
    "paint2 = \"24 small tubes (12ml, or .4 ounces) of a wide variety of colors. I am just trying to get back into some creative projects, and I thought I would refresh my stash of paint. If I knew I would be getting into bigger projects, I would buy larger containers. When I saw that this was a set of small tubes, I thought it would be perfect for me as I didn't want to any to go to waste. It is enough to start dabbling again without spending a lot of money to buy larger amounts. Comes with 3 basic paint brushes, too. All of the tubes in my package look good. I pressed all of them, and they feel soft. I opened up half dozen, and those were all fine. Hopefully remainder are good. I think this is a nice kit to have if you want to dabble, or as an add on to a themed gift.\"\n",
    "\n",
    "paint_reviews = [pd.Series([\"Acrylic Paint Set\", paint1, scoring_code(paint1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"Acrylic Paint Set\", paint2, scoring_code(paint2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(paint_reviews, ignore_index=True)\n",
    "\n",
    "gatorade1 = \"There is nothing classic about this vile wretched drink. I purchased these hoping to recapture the classic refreshing, revitalizing, experience from my athletic Highschool days. I am beside myself on the lack of transparency in the advertisement (no mention of small bottles in the title) and i find it misleading to call this product classic. It is clearly smaller than the standard classic gatorade and the flavor is something I would not wish on my worst enemy. This is nothing less than an atrocity.\"\n",
    "gatorade2 = \"I depend on this drink to keep me hydrated and my body systems in balance. Since I am diabetic, this is a low-calorie, tasty way to keep me going. And this is my most favorite Gatorade flavor\"\n",
    "\n",
    "gatorade_reviews = [pd.Series([\"Gatorade Thirst Quencher\", gatorade1, scoring_code(gatorade1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"Gatorade Thirst Quencher\", gatorade2, scoring_code(gatorade2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(gatorade_reviews, ignore_index=True)\n",
    "\n",
    "earmuffs1 = \"Maybe Iâ€™m just not that sharp but I expected menâ€™s Bluetooth earmuffs would have speakers in them and connect to my phone. Theyâ€™re just earmuffs. Theyâ€™re nice and comfortable but I could have gotten just earmuffs for less than half of the price of these.\"\n",
    "\n",
    "earmuffs2 = \"I bought a pair of these in D,C, in November from a street vendor. For a south Texan, D.C. in November was unbearable; it was cold with incessant wind and little sunshine. After I purchased these from the Pentagon City metro stop vendor, my last week in the Capital City was more than bearable. I spent hours on the Mall going from Smithsonian to Smithsonian. I spent hours in Arlington Cemetery as well as walking around Georgetown and the canal district. They are easy to don, although it takes both hands to put on. Doffing these ear muffs is even easier: use one hand to pull back the 'yoke' at the back of your head, fold them using the inherent twist and collapse feature with one hand, and they easily fit in a winter coat pocket without too much bulk. Combine these behind the head muffs with a tight weave winter cap and touch screen winter gloves, and you'll stay as warm as possible without feeling like Randy from 'A Christmas Story' These have been such a great addition to my Winter wardrobe, even in South Texas. that I stuffed them in stockings for my family, albeit after the holiday season. You won't be disappointed. And, as an added bonus for all your gotta-keep-my-coiffure-perfect friends and family members, these muffs sit on the ears, but the suspension rides on the occipital bone. If the temperatures are pleasant enough, you won't muss your hair. But the temperatures require a stocking cap, ymmv, Highly recommended.\"\n",
    "\n",
    "earmuffs_reviews = [pd.Series([\"180s Fleece Behind-the-Head Earmuffs\", earmuffs1, scoring_code(earmuffs1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"180s Fleece Behind-the-Head Earmuffs\", earmuffs2, scoring_code(earmuffs2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(earmuffs_reviews, ignore_index=True)\n",
    "\n",
    "echo1 = \"I bought the new echo plus during the black Friday sale this weekend to make use of the Line In feature which I was disappointed that my second generation echo I purchased last year didnt have. I was so excited to see that this changed this year with the new generation... EXCEPT it doest work!! The alexa software that you need to configure it as a 'line in' and not a 'line out' doesnt function, and according to the tech that assisted me, this has been a common problem with the device. I bought it for this reason, as advertised by amazon, and it doest work. The options I were given by the tech was essentially to wait and hope it gets fixed in the future, return it and lose out on the black friday deal if it is fixed in the future and wanted to buy it again at that time once it is, or wait and waste $109 dollars if it isnt fixed in the future once I pass the return window. All for an issue that is 100% AMAZON'S FAULT!! FALSE ADVERTISING and HORRIBLE CUSTOMER SERVICE like I have never experience before from amazon from a problem THEY inflicted and CAN remedy if they choose too! I asked for an extended return window, if they can honor the black friday price if I was to return it and buy it again in the future, and a refund/discount on the product due to it essentially being defective for my purposes, and each request was flat out REJECTED. When I asked to speak to someone else, that wasNOT PERMITTED either. SHAME ON YOU AMAZON, SHAME!!!\"\n",
    "echo2 = \"Short & Sweet - For what it is, this device is amazing. Performance is quick, audio is great, and the built-in Zigbee hub works quite well.\"\n",
    "\n",
    "echo_reviews = [pd.Series([\"Echo Plus (2nd Gen) with Philips Hue Bulb\", echo1, scoring_code(echo1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"Echo Plus (2nd Gen) with Philips Hue Bulb \", echo2, scoring_code(echo2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(echo_reviews, ignore_index=True)\n",
    "\n",
    "adidas1 = \"I used to love classic adidas shoes but these HURT my heel! The back goes up so high it drills into my skin when I walk.\"\n",
    "adidas2 = \"Great running shoe right out of the box! Highly recommended it......love this shoe. I run 40-50 miles a week.\"\n",
    "\n",
    "adidas_reviews = [pd.Series([\"adidas Women's Grand Court Sneaker\", adidas1, scoring_code(adidas1)], index=amazon_df.columns),\n",
    "                   pd.Series([\"adidas Women's Grand Court Sneaker\", adidas2, scoring_code(adidas2)], index=amazon_df.columns)]\n",
    "amazon_df = amazon_df.append(adidas_reviews, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Reviewed</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple AirPods with Charging Case</td>\n",
       "      <td>We bought a brand new set of AirPods for 159. ...</td>\n",
       "      <td>[(First pers plural, 0.032325493699025404), (T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple AirPods with Charging Case</td>\n",
       "      <td>These AirPods are amazing they automatically p...</td>\n",
       "      <td>[(Impersonal pronouns, 0.006211180124223602), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NutriBullet</td>\n",
       "      <td>Very loud! I didn't think noise would ever be ...</td>\n",
       "      <td>[(Total function words, 0.361022922058207), (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NutriBullet</td>\n",
       "      <td>This is my third NB purchase and by far the mo...</td>\n",
       "      <td>[(Total function words, 0.32572424341974016), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLIF BAR - Energy Bars</td>\n",
       "      <td>Tastes terrible and super sweet</td>\n",
       "      <td>[(Total function words, 0.3084179131240047), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CLIF BAR - Energy Bars</td>\n",
       "      <td>shipped fast, product was in perfect order and...</td>\n",
       "      <td>[(Total function words, 0.36854884863779364), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charmin Ultra Soft Cushiony Touch Toilet Paper</td>\n",
       "      <td>Rolls are way too narrow and not worth the cos...</td>\n",
       "      <td>[(Total function words, 0.26911576188186204), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Charmin Ultra Soft Cushiony Touch Toilet Paper</td>\n",
       "      <td>I've been using this toilet paper for several ...</td>\n",
       "      <td>[(Total function words, 0.40842370000446765), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pantene Moisturizing Shampoo and Conditioner</td>\n",
       "      <td>Never been a fan of pantene but read some good...</td>\n",
       "      <td>[(Negations, 0.019801980198019802), (Total fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pantene Moisturizing Shampoo and Conditioner</td>\n",
       "      <td>My fav, go-to shampoo and conditioner for year...</td>\n",
       "      <td>[(Total function words, 0.3026626173355583), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Acrylic Paint Set</td>\n",
       "      <td>Half of the colors are dry. I did not realized...</td>\n",
       "      <td>[(Total function words, 0.35958968527664015), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Acrylic Paint Set</td>\n",
       "      <td>24 small tubes (12ml, or .4 ounces) of a wide ...</td>\n",
       "      <td>[(Total function words, 0.36942761724950995), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gatorade Thirst Quencher</td>\n",
       "      <td>There is nothing classic about this vile wretc...</td>\n",
       "      <td>[(Total function words, 0.36890239674963243), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gatorade Thirst Quencher</td>\n",
       "      <td>I depend on this drink to keep me hydrated and...</td>\n",
       "      <td>[(First pers singular, 0.10810810810810811), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>180s Fleece Behind-the-Head Earmuffs</td>\n",
       "      <td>Maybe Iâ€™m just not that sharp but I expected m...</td>\n",
       "      <td>[(Tentative, 0.022222222222222223), (Total fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>180s Fleece Behind-the-Head Earmuffs</td>\n",
       "      <td>I bought a pair of these in D,C, in November f...</td>\n",
       "      <td>[(First pers singular, 0.019762845849802372), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Echo Plus (2nd Gen) with Philips Hue Bulb</td>\n",
       "      <td>I bought the new echo plus during the black Fr...</td>\n",
       "      <td>[(First pers singular, 0.043478260869565216), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Echo Plus (2nd Gen) with Philips Hue Bulb</td>\n",
       "      <td>Short &amp; Sweet - For what it is, this device is...</td>\n",
       "      <td>[(Total function words, 0.28017566563357466), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adidas Women's Grand Court Sneaker</td>\n",
       "      <td>I used to love classic adidas shoes but these ...</td>\n",
       "      <td>[(First pers singular, 0.07692307692307693), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adidas Women's Grand Court Sneaker</td>\n",
       "      <td>Great running shoe right out of the box! Highl...</td>\n",
       "      <td>[(Total function words, 0.4150659539157915), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Product Reviewed  \\\n",
       "0                 Apple AirPods with Charging Case   \n",
       "1                 Apple AirPods with Charging Case   \n",
       "2                                      NutriBullet   \n",
       "3                                      NutriBullet   \n",
       "4                           CLIF BAR - Energy Bars   \n",
       "5                           CLIF BAR - Energy Bars   \n",
       "6   Charmin Ultra Soft Cushiony Touch Toilet Paper   \n",
       "7   Charmin Ultra Soft Cushiony Touch Toilet Paper   \n",
       "8     Pantene Moisturizing Shampoo and Conditioner   \n",
       "9     Pantene Moisturizing Shampoo and Conditioner   \n",
       "10                               Acrylic Paint Set   \n",
       "11                               Acrylic Paint Set   \n",
       "12                        Gatorade Thirst Quencher   \n",
       "13                        Gatorade Thirst Quencher   \n",
       "14            180s Fleece Behind-the-Head Earmuffs   \n",
       "15            180s Fleece Behind-the-Head Earmuffs   \n",
       "16       Echo Plus (2nd Gen) with Philips Hue Bulb   \n",
       "17      Echo Plus (2nd Gen) with Philips Hue Bulb    \n",
       "18              adidas Women's Grand Court Sneaker   \n",
       "19              adidas Women's Grand Court Sneaker   \n",
       "\n",
       "                                             Sentence  \\\n",
       "0   We bought a brand new set of AirPods for 159. ...   \n",
       "1   These AirPods are amazing they automatically p...   \n",
       "2   Very loud! I didn't think noise would ever be ...   \n",
       "3   This is my third NB purchase and by far the mo...   \n",
       "4                     Tastes terrible and super sweet   \n",
       "5   shipped fast, product was in perfect order and...   \n",
       "6   Rolls are way too narrow and not worth the cos...   \n",
       "7   I've been using this toilet paper for several ...   \n",
       "8   Never been a fan of pantene but read some good...   \n",
       "9   My fav, go-to shampoo and conditioner for year...   \n",
       "10  Half of the colors are dry. I did not realized...   \n",
       "11  24 small tubes (12ml, or .4 ounces) of a wide ...   \n",
       "12  There is nothing classic about this vile wretc...   \n",
       "13  I depend on this drink to keep me hydrated and...   \n",
       "14  Maybe Iâ€™m just not that sharp but I expected m...   \n",
       "15  I bought a pair of these in D,C, in November f...   \n",
       "16  I bought the new echo plus during the black Fr...   \n",
       "17  Short & Sweet - For what it is, this device is...   \n",
       "18  I used to love classic adidas shoes but these ...   \n",
       "19  Great running shoe right out of the box! Highl...   \n",
       "\n",
       "                                                Score  \n",
       "0   [(First pers plural, 0.032325493699025404), (T...  \n",
       "1   [(Impersonal pronouns, 0.006211180124223602), ...  \n",
       "2   [(Total function words, 0.361022922058207), (F...  \n",
       "3   [(Total function words, 0.32572424341974016), ...  \n",
       "4   [(Total function words, 0.3084179131240047), (...  \n",
       "5   [(Total function words, 0.36854884863779364), ...  \n",
       "6   [(Total function words, 0.26911576188186204), ...  \n",
       "7   [(Total function words, 0.40842370000446765), ...  \n",
       "8   [(Negations, 0.019801980198019802), (Total fun...  \n",
       "9   [(Total function words, 0.3026626173355583), (...  \n",
       "10  [(Total function words, 0.35958968527664015), ...  \n",
       "11  [(Total function words, 0.36942761724950995), ...  \n",
       "12  [(Total function words, 0.36890239674963243), ...  \n",
       "13  [(First pers singular, 0.10810810810810811), (...  \n",
       "14  [(Tentative, 0.022222222222222223), (Total fun...  \n",
       "15  [(First pers singular, 0.019762845849802372), ...  \n",
       "16  [(First pers singular, 0.043478260869565216), ...  \n",
       "17  [(Total function words, 0.28017566563357466), ...  \n",
       "18  [(First pers singular, 0.07692307692307693), (...  \n",
       "19  [(Total function words, 0.4150659539157915), (...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.to_csv('amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_scores = []\n",
    "positive_reviews_scores = []\n",
    "\n",
    "for i in range(0,len(amazon_df),2):\n",
    "    negative_reviews_scores.append(amazon_df[\"Score\"][i])\n",
    "    \n",
    "for i in range(1,len(amazon_df),2):\n",
    "    positive_reviews_scores.append(amazon_df[\"Score\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Reviewed</th>\n",
       "      <th>5 Star Review</th>\n",
       "      <th>5 Star Review (Score)</th>\n",
       "      <th>1 Star Review</th>\n",
       "      <th>1 Star Review (Score)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple AirPods with Charging Case</td>\n",
       "      <td>These AirPods are amazing they automatically p...</td>\n",
       "      <td>[(Impersonal pronouns, 0.006211180124223602), ...</td>\n",
       "      <td>We bought a brand new set of AirPods for 159. ...</td>\n",
       "      <td>[(First pers plural, 0.032325493699025404), (T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NutriBullet</td>\n",
       "      <td>This is my third NB purchase and by far the mo...</td>\n",
       "      <td>[(Total function words, 0.32572424341974016), ...</td>\n",
       "      <td>Very loud! I didn't think noise would ever be ...</td>\n",
       "      <td>[(Total function words, 0.361022922058207), (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLIF BAR - Energy Bars</td>\n",
       "      <td>shipped fast, product was in perfect order and...</td>\n",
       "      <td>[(Total function words, 0.36854884863779364), ...</td>\n",
       "      <td>Tastes terrible and super sweet</td>\n",
       "      <td>[(Total function words, 0.3084179131240047), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charmin Ultra Soft Cushiony Touch Toilet Paper</td>\n",
       "      <td>I've been using this toilet paper for several ...</td>\n",
       "      <td>[(Total function words, 0.40842370000446765), ...</td>\n",
       "      <td>Rolls are way too narrow and not worth the cos...</td>\n",
       "      <td>[(Total function words, 0.26911576188186204), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pantene Moisturizing Shampoo and Conditioner</td>\n",
       "      <td>My fav, go-to shampoo and conditioner for year...</td>\n",
       "      <td>[(Total function words, 0.3026626173355583), (...</td>\n",
       "      <td>Never been a fan of pantene but read some good...</td>\n",
       "      <td>[(Negations, 0.019801980198019802), (Total fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acrylic Paint Set</td>\n",
       "      <td>24 small tubes (12ml, or .4 ounces) of a wide ...</td>\n",
       "      <td>[(Total function words, 0.36942761724950995), ...</td>\n",
       "      <td>Half of the colors are dry. I did not realized...</td>\n",
       "      <td>[(Total function words, 0.35958968527664015), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gatorade Thirst Quencher</td>\n",
       "      <td>I depend on this drink to keep me hydrated and...</td>\n",
       "      <td>[(First pers singular, 0.10810810810810811), (...</td>\n",
       "      <td>There is nothing classic about this vile wretc...</td>\n",
       "      <td>[(Total function words, 0.36890239674963243), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180s Fleece Behind-the-Head Earmuffs</td>\n",
       "      <td>I bought a pair of these in D,C, in November f...</td>\n",
       "      <td>[(First pers singular, 0.019762845849802372), ...</td>\n",
       "      <td>Maybe Iâ€™m just not that sharp but I expected m...</td>\n",
       "      <td>[(Tentative, 0.022222222222222223), (Total fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Echo Plus (2nd Gen) with Philips Hue Bulb</td>\n",
       "      <td>Short &amp; Sweet - For what it is, this device is...</td>\n",
       "      <td>[(Total function words, 0.28017566563357466), ...</td>\n",
       "      <td>I bought the new echo plus during the black Fr...</td>\n",
       "      <td>[(First pers singular, 0.043478260869565216), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adidas Women's Grand Court Sneaker</td>\n",
       "      <td>Great running shoe right out of the box! Highl...</td>\n",
       "      <td>[(Total function words, 0.4150659539157915), (...</td>\n",
       "      <td>I used to love classic adidas shoes but these ...</td>\n",
       "      <td>[(First pers singular, 0.07692307692307693), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Product Reviewed  \\\n",
       "0                Apple AirPods with Charging Case   \n",
       "1                                     NutriBullet   \n",
       "2                          CLIF BAR - Energy Bars   \n",
       "3  Charmin Ultra Soft Cushiony Touch Toilet Paper   \n",
       "4    Pantene Moisturizing Shampoo and Conditioner   \n",
       "5                               Acrylic Paint Set   \n",
       "6                        Gatorade Thirst Quencher   \n",
       "7            180s Fleece Behind-the-Head Earmuffs   \n",
       "8       Echo Plus (2nd Gen) with Philips Hue Bulb   \n",
       "9              adidas Women's Grand Court Sneaker   \n",
       "\n",
       "                                       5 Star Review  \\\n",
       "0  These AirPods are amazing they automatically p...   \n",
       "1  This is my third NB purchase and by far the mo...   \n",
       "2  shipped fast, product was in perfect order and...   \n",
       "3  I've been using this toilet paper for several ...   \n",
       "4  My fav, go-to shampoo and conditioner for year...   \n",
       "5  24 small tubes (12ml, or .4 ounces) of a wide ...   \n",
       "6  I depend on this drink to keep me hydrated and...   \n",
       "7  I bought a pair of these in D,C, in November f...   \n",
       "8  Short & Sweet - For what it is, this device is...   \n",
       "9  Great running shoe right out of the box! Highl...   \n",
       "\n",
       "                               5 Star Review (Score)  \\\n",
       "0  [(Impersonal pronouns, 0.006211180124223602), ...   \n",
       "1  [(Total function words, 0.32572424341974016), ...   \n",
       "2  [(Total function words, 0.36854884863779364), ...   \n",
       "3  [(Total function words, 0.40842370000446765), ...   \n",
       "4  [(Total function words, 0.3026626173355583), (...   \n",
       "5  [(Total function words, 0.36942761724950995), ...   \n",
       "6  [(First pers singular, 0.10810810810810811), (...   \n",
       "7  [(First pers singular, 0.019762845849802372), ...   \n",
       "8  [(Total function words, 0.28017566563357466), ...   \n",
       "9  [(Total function words, 0.4150659539157915), (...   \n",
       "\n",
       "                                       1 Star Review  \\\n",
       "0  We bought a brand new set of AirPods for 159. ...   \n",
       "1  Very loud! I didn't think noise would ever be ...   \n",
       "2                    Tastes terrible and super sweet   \n",
       "3  Rolls are way too narrow and not worth the cos...   \n",
       "4  Never been a fan of pantene but read some good...   \n",
       "5  Half of the colors are dry. I did not realized...   \n",
       "6  There is nothing classic about this vile wretc...   \n",
       "7  Maybe Iâ€™m just not that sharp but I expected m...   \n",
       "8  I bought the new echo plus during the black Fr...   \n",
       "9  I used to love classic adidas shoes but these ...   \n",
       "\n",
       "                               1 Star Review (Score)  \n",
       "0  [(First pers plural, 0.032325493699025404), (T...  \n",
       "1  [(Total function words, 0.361022922058207), (F...  \n",
       "2  [(Total function words, 0.3084179131240047), (...  \n",
       "3  [(Total function words, 0.26911576188186204), ...  \n",
       "4  [(Negations, 0.019801980198019802), (Total fun...  \n",
       "5  [(Total function words, 0.35958968527664015), ...  \n",
       "6  [(Total function words, 0.36890239674963243), ...  \n",
       "7  [(Tentative, 0.022222222222222223), (Total fun...  \n",
       "8  [(First pers singular, 0.043478260869565216), ...  \n",
       "9  [(First pers singular, 0.07692307692307693), (...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "products = []\n",
    "negative_reviews = []\n",
    "positive_reviews = []\n",
    "negative_reviews_score = []\n",
    "positive_reviews_score = []\n",
    "\n",
    "for i in range(0,len(amazon_df),2):\n",
    "    products.append(amazon_df[\"Product Reviewed\"][i])\n",
    "    \n",
    "for i in range(0,len(amazon_df),2):\n",
    "    negative_reviews.append(amazon_df[\"Sentence\"][i])\n",
    "    negative_reviews_score.append(amazon_df[\"Score\"][i])\n",
    "    \n",
    "for i in range(1,len(amazon_df),2):\n",
    "    positive_reviews.append(amazon_df[\"Sentence\"][i])\n",
    "    positive_reviews_score.append(amazon_df[\"Score\"][i])\n",
    "\n",
    "reviews = {'Product Reviewed': products,\n",
    "        '5 Star Review':positive_reviews,\n",
    "        '5 Star Review (Score)':positive_reviews_score,\n",
    "        '1 Star Review':negative_reviews,\n",
    "        '1 Star Review (Score)':negative_reviews_score} \n",
    "   \n",
    "reviews_df = pd.DataFrame(reviews) \n",
    "reviews_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('amazon_reviews_scored.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization (Prepping the Data)\n",
    "\n",
    "Making graphs on an external tool, Datawrapper (https://www.datawrapper.de/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Total function words', 'Total pronouns', 'Personal pronouns', 'First pers singular', 'First pers plural', 'Second person', 'Third pers singular', 'Third pers plural', 'Impersonal pronouns', 'Articles', 'Prepositions', 'Auxiliary verbs', 'Common Adverbs', 'Conjunctions', 'Negations', 'Common verbs', 'Common adjectives', 'Comparisons', 'Interrogatives', 'Numbers', 'Quantifiers', 'Affective processes', 'Positive emotion', 'Negative emotion', 'Anxiety', 'Anger', 'Sadness', 'Social processes', 'Family', 'Friends', 'Female references', 'Male references', 'Cognitive processes', 'Insight', 'Causation', 'Discrepancy', 'Tentative', 'Certainty', 'Differentiation', 'Perceptual processes', 'See', 'Hear', 'Feel', 'Biological processes', 'Body', 'Health', 'Sexual', 'Ingestion', 'Affiliation', 'Achievement', 'Power', 'Reward', 'Risk', 'Past focus', 'Present focus', 'Future focus', 'Relativity ', 'Motion', 'Space', 'Time', 'Work', 'Leisure', 'Home', 'Money', 'Religion', 'Death', 'Swear words', 'Netspeak', 'Assent', 'Nonfluencies ', 'Fillers'] 71\n"
     ]
    }
   ],
   "source": [
    "liwccategories = []\n",
    "for ind in df.index:\n",
    "    liwccategories.append(df[\"Category\"][ind])\n",
    "print(liwccategories, len(liwccategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews=[[('Impersonal pronouns', 0.006211180124223602), ('Total function words', 0.3710216546676471), ('Present focus', 0.012422360248447204), ('Third pers plural', 0.018633540372670808), ('Prepositions', 0.0610930502120442), ('Future focus', 0.006211180124223602), ('Second person', 0.048576977060678386), ('Total pronouns', 0.012422360248447204), ('Space', 0.012422360248447204), ('Conjunctions', 0.024844720496894408), ('Interrogatives', 0.018633540372670808), ('Reward', 0.006211180124223602), ('Hear', 0.024844720496894408), ('Auxiliary verbs', 0.006211180124223602), ('Time', 0.006211180124223602), ('Social processes', 0.011201012732048913), ('Articles', 0.006211180124223602), ('Quantifiers', 0.006211180124223602), ('Causation', 0.006211180124223602), ('Comparisons', 0.006211180124223602), ('Numbers', 0.006211180124223602), ('First pers singular', 0.006211180124223602), ('Discrepancy', 0.006211180124223602), ('Perceptual processes', 0.00463273943809684)],\n",
    "          [('Total function words', 0.32572424341974016), ('Present focus', 0.017094017094017096), ('Conjunctions', 0.06837606837606838), ('Prepositions', 0.07692307692307693), ('Quantifiers', 0.02564102564102564), ('Numbers', 0.017094017094017096), ('Articles', 0.017094017094017096), ('Interrogatives', 0.008547008547008548), ('Motion', 0.010243483491488658), ('First pers singular', 0.017094017094017096), ('Causation', 0.02564102564102564), ('Auxiliary verbs', 0.02564102564102564), ('Affiliation', 0.006891297399653198), ('Comparisons', 0.017094017094017096), ('Negations', 0.008547008547008548), ('Total pronouns', 0.008547008547008548), ('Common adjectives', 0.008547008547008548), ('Third pers plural', 0.008547008547008548)]\n",
    "          ,[('Total function words', 0.40842370000446765), ('First pers plural', 0.016221099412348516), ('Causation', 0.03488372093023256), ('Quantifiers', 0.011627906976744186), ('Present focus', 0.023255813953488372), ('First pers singular', 0.03488372093023256), ('Prepositions', 0.03488372093023256), ('Cognitive processes', 0.011627906976744186), ('Conjunctions', 0.011627906976744186), ('Total pronouns', 0.011627906976744186), ('Negations', 0.011627906976744186), ('Common verbs', 0.011627906976744186)]\n",
    "          ,[('Total function words', 0.3026626173355583), ('Conjunctions', 0.04878048780487805), ('Causation', 0.024390243902439025), ('First pers singular', 0.024390243902439025), ('Prepositions', 0.0658388125898768), ('Certainty', 0.04878048780487805), ('Motion', 0.04878048780487805), ('Comparisons', 0.024390243902439025), ('First pers plural', 0.010823015738245125)]\n",
    "          ,[('Total function words', 0.36942761724950995), ('Quantifiers', 0.012738853503184714), ('Prepositions', 0.04712600402783374), ('First pers singular', 0.08280254777070063), ('Auxiliary verbs', 0.012738853503184714), ('Space', 0.01910828025477707), ('Conjunctions', 0.03184713375796178), ('Insight', 0.01910828025477707), ('Discrepancy', 0.025477707006369428), ('Comparisons', 0.01910828025477707), ('Interrogatives', 0.006369426751592357), ('See', 0.006369426751592357), ('Causation', 0.006369426751592357), ('Motion', 0.006369426751592357), ('Present focus', 0.01910828025477707), ('Social processes', 0.006369426751592357), ('Common verbs', 0.004112816280312351), ('Perceptual processes', 0.006369426751592357), ('Positive emotion', 0.01910828025477707), ('Total pronouns', 0.008329725576610015), ('Third pers plural', 0.006369426751592357), ('Impersonal pronouns', 0.006369426751592357), ('Second person', 0.006369426751592357), ('Articles', 0.006369426751592357)]\n",
    "          ,[('First pers singular', 0.10810810810810811), ('Total function words', 0.34950421950462135), ('Conjunctions', 0.05405405405405406), ('Space', 0.02702702702702703), ('Past focus', 0.02702702702702703), ('Auxiliary verbs', 0.02702702702702703), ('Present focus', 0.05405405405405406), ('Prepositions', 0.02702702702702703), ('Motion', 0.02702702702702703)]\n",
    "          ,[('First pers singular', 0.019762845849802372), ('Total function words', 0.283445884014915), ('Prepositions', 0.10077848450958396), ('Impersonal pronouns', 0.02766798418972332), ('Space', 0.03162055335968379), ('Causation', 0.011857707509881422), ('Conjunctions', 0.05138339920948617), ('Quantifiers', 0.007905138339920948), ('Comparisons', 0.015810276679841896), ('Third pers plural', 0.011857707509881422), ('Motion', 0.003952569169960474), ('Death', 0.003952569169960474), ('Present focus', 0.011857707509881422), ('Reward', 0.00276377955003522), ('Third pers singular', 0.003952569169960474), ('Body', 0.011857707509881422), ('Time', 0.011857707509881422), ('First pers plural', 0.0034063949830501644), ('Second person', 0.019762845849802372), ('Total pronouns', 0.007905138339920948), ('Feel', 0.003952569169960474), ('Auxiliary verbs', 0.003952569169960474), ('Articles', 0.003952569169960474), ('Assent', 0.0017917894778856226), ('Affiliation', 0.003952569169960474), ('Positive emotion', 0.003952569169960474)]\n",
    "          ,[('Total function words', 0.28017566563357466), ('Positive emotion', 0.038461538461538464), ('Causation', 0.038461538461538464), ('Interrogatives', 0.038461538461538464), ('Present focus', 0.15384615384615385), ('Conjunctions', 0.038461538461538464), ('Prepositions', 0.038461538461538464), ('Comparisons', 0.038461538461538464)]\n",
    "          ,[('Total function words', 0.4150659539157915), ('Prepositions', 0.10526315789473684), ('First pers singular', 0.05263157894736842), ('Numbers', 0.05263157894736842)],\n",
    "                 [('Total function words', 0.4150659539157915), ('Prepositions', 0.10526315789473684), ('First pers singular', 0.05263157894736842), ('Numbers', 0.05263157894736842)]]\n",
    "\n",
    "negative_reviews= [[('First pers plural', 0.032325493699025404), ('Total function words', 0.31475411575015133), ('Prepositions', 0.054465100510835814), ('Causation', 0.02654867256637168), ('Comparisons', 0.017699115044247787), ('Total pronouns', 0.03982300884955752), ('First pers singular', 0.05752212389380531), ('Hear', 0.004424778761061947), ('Conjunctions', 0.05752212389380531), ('Motion', 0.015396594352023887), ('Time', 0.008849557522123894), ('Tentative', 0.004424778761061947), ('Interrogatives', 0.017699115044247787), ('Past focus', 0.01327433628318584), ('Differentiation', 0.004424778761061947), ('Ingestion', 0.017699115044247787), ('Third pers plural', 0.035398230088495575), ('Articles', 0.01327433628318584), ('Space', 0.004424778761061947), ('Negations', 0.008849557522123894), ('Present focus', 0.004424778761061947), ('Auxiliary verbs', 0.004424778761061947), ('Impersonal pronouns', 0.004424778761061947)],\n",
    "                   [('Total function words', 0.361022922058207), ('First pers singular', 0.03), ('Insight', 0.01), ('Discrepancy', 0.01), ('Articles', 0.01), ('Conjunctions', 0.07), ('Present focus', 0.05), ('Third pers plural', 0.02), ('Space', 0.02), ('Prepositions', 0.06), ('Negations', 0.04), ('Second person', 0.01), ('Interrogatives', 0.01), ('First pers plural', 0.004668033812497192), ('Sadness', 0.0071390479439136225), ('Auxiliary verbs', 0.01)]\n",
    "                   ,[('Total function words', 0.3084179131240047), ('Conjunctions', 0.2), ('Positive emotion', 0.2)]\n",
    "                   ,[('Total function words', 0.26911576188186204), ('Present focus', 0.045454545454545456), ('Conjunctions', 0.045454545454545456), ('Negations', 0.09090909090909091), ('Prepositions', 0.045454545454545456), ('Space', 0.045454545454545456), ('Achievement', 0.045454545454545456), ('Auxiliary verbs', 0.045454545454545456), ('Body', 0.045454545454545456)]\n",
    "                   ,[('Negations', 0.019801980198019802), ('Total function words', 0.3987497667644932), ('Prepositions', 0.0297029702970297), ('Conjunctions', 0.06930693069306931), ('Positive emotion', 0.009900990099009901), ('Causation', 0.009900990099009901), ('Common adjectives', 0.009900990099009901), ('Comparisons', 0.0297029702970297), ('Numbers', 0.009900990099009901), ('Space', 0.02441857336725205), ('First pers singular', 0.039603960396039604), ('Cognitive processes', 0.009900990099009901), ('Present focus', 0.019801980198019802), ('Motion', 0.009900990099009901), ('Swear words', 0.009900990099009901), ('Achievement', 0.009900990099009901)]\n",
    "                   ,[('Total function words', 0.35958968527664015), ('Prepositions', 0.1111111111111111), ('Present focus', 0.05555555555555555), ('First pers singular', 0.05555555555555555), ('Past focus', 0.05555555555555555), ('Negations', 0.05555555555555555), ('Comparisons', 0.05555555555555555), ('Time', 0.05555555555555555)]\n",
    "                   ,[('Total function words', 0.36890239674963243), ('Present focus', 0.047619047619047616), ('First pers singular', 0.047619047619047616), ('Impersonal pronouns', 0.011904761904761904), ('Prepositions', 0.07142857142857142), ('Time', 0.011904761904761904), ('Auxiliary verbs', 0.011904761904761904), ('Total pronouns', 0.011904761904761904), ('Space', 0.023809523809523808), ('Past focus', 0.011904761904761904), ('Quantifiers', 0.011904761904761904), ('Conjunctions', 0.023809523809523808), ('Third pers plural', 0.023809523809523808), ('Discrepancy', 0.011904761904761904), ('Negations', 0.011904761904761904), ('Articles', 0.011904761904761904)]\n",
    "                   ,[('Tentative', 0.022222222222222223), ('Total function words', 0.3070063152760113), ('Negations', 0.022222222222222223), ('Conjunctions', 0.08888888888888889), ('First pers singular', 0.06666666666666667), ('Discrepancy', 0.044444444444444446), ('Auxiliary verbs', 0.044444444444444446), ('Space', 0.022222222222222223), ('Total pronouns', 0.022222222222222223), ('Positive emotion', 0.022222222222222223), ('Causation', 0.022222222222222223), ('Third pers plural', 0.022222222222222223), ('Prepositions', 0.022222222222222223), ('Impersonal pronouns', 0.022222222222222223)]\n",
    "                   ,[('First pers singular', 0.043478260869565216), ('Total function words', 0.3925471264735436), ('Prepositions', 0.0920245747549634), ('Interrogatives', 0.007246376811594203), ('First pers plural', 0.0016913165987308668), ('Space', 0.021739130434782608), ('Articles', 0.010869565217391304), ('Numbers', 0.0036231884057971015), ('Auxiliary verbs', 0.010869565217391304), ('Conjunctions', 0.06521739130434782), ('Second person', 0.007246376811594203), ('Negations', 0.007246376811594203), ('Assent', 0.001453907182975311), ('Causation', 0.014492753623188406), ('Cognitive processes', 0.0036231884057971015), ('Present focus', 0.010869565217391304), ('Past focus', 0.0036231884057971015), ('Third pers plural', 0.010869565217391304), ('Impersonal pronouns', 0.0036231884057971015)]\n",
    "                   ,[('First pers singular', 0.07692307692307693), ('First pers plural', 0.017067063279540388), ('Total function words', 0.2760531864455037), ('Positive emotion', 0.038461538461538464), ('Conjunctions', 0.07692307692307693), ('Impersonal pronouns', 0.038461538461538464), ('Negative emotion', 0.038461538461538464), ('Prepositions', 0.038461538461538464), ('Motion', 0.027951054765315533), ('Space', 0.038461538461538464), ('Interrogatives', 0.038461538461538464)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_df = pd.DataFrame(columns = products, index = liwccategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "def fill_chart(df_name, review_type, product_index, product_name):\n",
    "    def review_vis(review_type, index): \n",
    "        categories = []\n",
    "        scores = []\n",
    "        for rev in review_type[index]:\n",
    "            category, score = rev[0], rev[1]\n",
    "            categories.append(category)\n",
    "            scores.append(score)\n",
    "        return categories, scores\n",
    "\n",
    "    categories, scores = review_vis(review_type, product_index)\n",
    "\n",
    "    for ind in categories:\n",
    "        index = categories.index(ind)\n",
    "        df_name[product_name][ind] = scores[index]\n",
    "        \n",
    "for prod in products:\n",
    "    fill_chart(positive_data_df, positive_reviews, products.index(prod), prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple AirPods with Charging Case</th>\n",
       "      <th>NutriBullet</th>\n",
       "      <th>CLIF BAR - Energy Bars</th>\n",
       "      <th>Charmin Ultra Soft Cushiony Touch Toilet Paper</th>\n",
       "      <th>Pantene Moisturizing Shampoo and Conditioner</th>\n",
       "      <th>Acrylic Paint Set</th>\n",
       "      <th>Gatorade Thirst Quencher</th>\n",
       "      <th>180s Fleece Behind-the-Head Earmuffs</th>\n",
       "      <th>Echo Plus (2nd Gen) with Philips Hue Bulb</th>\n",
       "      <th>adidas Women's Grand Court Sneaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total function words</th>\n",
       "      <td>0.371022</td>\n",
       "      <td>0.325724</td>\n",
       "      <td>0.408424</td>\n",
       "      <td>0.302663</td>\n",
       "      <td>0.369428</td>\n",
       "      <td>0.349504</td>\n",
       "      <td>0.283446</td>\n",
       "      <td>0.280176</td>\n",
       "      <td>0.415066</td>\n",
       "      <td>0.415066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total pronouns</th>\n",
       "      <td>0.0124224</td>\n",
       "      <td>0.00854701</td>\n",
       "      <td>0.0116279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00832973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00790514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal pronouns</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First pers singular</th>\n",
       "      <td>0.00621118</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.0348837</td>\n",
       "      <td>0.0243902</td>\n",
       "      <td>0.0828025</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.0197628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0526316</td>\n",
       "      <td>0.0526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First pers plural</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0162211</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00340639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swear words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netspeak</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00179179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfluencies</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fillers</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Apple AirPods with Charging Case NutriBullet  \\\n",
       "Total function words                         0.371022    0.325724   \n",
       "Total pronouns                              0.0124224  0.00854701   \n",
       "Personal pronouns                                 NaN         NaN   \n",
       "First pers singular                        0.00621118    0.017094   \n",
       "First pers plural                                 NaN         NaN   \n",
       "...                                               ...         ...   \n",
       "Swear words                                       NaN         NaN   \n",
       "Netspeak                                          NaN         NaN   \n",
       "Assent                                            NaN         NaN   \n",
       "Nonfluencies                                      NaN         NaN   \n",
       "Fillers                                           NaN         NaN   \n",
       "\n",
       "                     CLIF BAR - Energy Bars  \\\n",
       "Total function words               0.408424   \n",
       "Total pronouns                    0.0116279   \n",
       "Personal pronouns                       NaN   \n",
       "First pers singular               0.0348837   \n",
       "First pers plural                 0.0162211   \n",
       "...                                     ...   \n",
       "Swear words                             NaN   \n",
       "Netspeak                                NaN   \n",
       "Assent                                  NaN   \n",
       "Nonfluencies                            NaN   \n",
       "Fillers                                 NaN   \n",
       "\n",
       "                     Charmin Ultra Soft Cushiony Touch Toilet Paper  \\\n",
       "Total function words                                       0.302663   \n",
       "Total pronouns                                                  NaN   \n",
       "Personal pronouns                                               NaN   \n",
       "First pers singular                                       0.0243902   \n",
       "First pers plural                                          0.010823   \n",
       "...                                                             ...   \n",
       "Swear words                                                     NaN   \n",
       "Netspeak                                                        NaN   \n",
       "Assent                                                          NaN   \n",
       "Nonfluencies                                                    NaN   \n",
       "Fillers                                                         NaN   \n",
       "\n",
       "                     Pantene Moisturizing Shampoo and Conditioner  \\\n",
       "Total function words                                     0.369428   \n",
       "Total pronouns                                         0.00832973   \n",
       "Personal pronouns                                             NaN   \n",
       "First pers singular                                     0.0828025   \n",
       "First pers plural                                             NaN   \n",
       "...                                                           ...   \n",
       "Swear words                                                   NaN   \n",
       "Netspeak                                                      NaN   \n",
       "Assent                                                        NaN   \n",
       "Nonfluencies                                                  NaN   \n",
       "Fillers                                                       NaN   \n",
       "\n",
       "                     Acrylic Paint Set Gatorade Thirst Quencher  \\\n",
       "Total function words          0.349504                 0.283446   \n",
       "Total pronouns                     NaN               0.00790514   \n",
       "Personal pronouns                  NaN                      NaN   \n",
       "First pers singular           0.108108                0.0197628   \n",
       "First pers plural                  NaN               0.00340639   \n",
       "...                                ...                      ...   \n",
       "Swear words                        NaN                      NaN   \n",
       "Netspeak                           NaN                      NaN   \n",
       "Assent                             NaN               0.00179179   \n",
       "Nonfluencies                       NaN                      NaN   \n",
       "Fillers                            NaN                      NaN   \n",
       "\n",
       "                     180s Fleece Behind-the-Head Earmuffs  \\\n",
       "Total function words                             0.280176   \n",
       "Total pronouns                                        NaN   \n",
       "Personal pronouns                                     NaN   \n",
       "First pers singular                                   NaN   \n",
       "First pers plural                                     NaN   \n",
       "...                                                   ...   \n",
       "Swear words                                           NaN   \n",
       "Netspeak                                              NaN   \n",
       "Assent                                                NaN   \n",
       "Nonfluencies                                          NaN   \n",
       "Fillers                                               NaN   \n",
       "\n",
       "                     Echo Plus (2nd Gen) with Philips Hue Bulb  \\\n",
       "Total function words                                  0.415066   \n",
       "Total pronouns                                             NaN   \n",
       "Personal pronouns                                          NaN   \n",
       "First pers singular                                  0.0526316   \n",
       "First pers plural                                          NaN   \n",
       "...                                                        ...   \n",
       "Swear words                                                NaN   \n",
       "Netspeak                                                   NaN   \n",
       "Assent                                                     NaN   \n",
       "Nonfluencies                                               NaN   \n",
       "Fillers                                                    NaN   \n",
       "\n",
       "                     adidas Women's Grand Court Sneaker  \n",
       "Total function words                           0.415066  \n",
       "Total pronouns                                      NaN  \n",
       "Personal pronouns                                   NaN  \n",
       "First pers singular                           0.0526316  \n",
       "First pers plural                                   NaN  \n",
       "...                                                 ...  \n",
       "Swear words                                         NaN  \n",
       "Netspeak                                            NaN  \n",
       "Assent                                              NaN  \n",
       "Nonfluencies                                        NaN  \n",
       "Fillers                                             NaN  \n",
       "\n",
       "[71 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data_df.to_csv(\"positive_reviews_breakdown.csv\")\n",
    "positive_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data_df = pd.DataFrame(columns = products, index = liwccategories)\n",
    "for prod in products:\n",
    "    fill_chart(negative_data_df, negative_reviews, products.index(prod), prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple AirPods with Charging Case</th>\n",
       "      <th>NutriBullet</th>\n",
       "      <th>CLIF BAR - Energy Bars</th>\n",
       "      <th>Charmin Ultra Soft Cushiony Touch Toilet Paper</th>\n",
       "      <th>Pantene Moisturizing Shampoo and Conditioner</th>\n",
       "      <th>Acrylic Paint Set</th>\n",
       "      <th>Gatorade Thirst Quencher</th>\n",
       "      <th>180s Fleece Behind-the-Head Earmuffs</th>\n",
       "      <th>Echo Plus (2nd Gen) with Philips Hue Bulb</th>\n",
       "      <th>adidas Women's Grand Court Sneaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total function words</th>\n",
       "      <td>0.314754</td>\n",
       "      <td>0.361023</td>\n",
       "      <td>0.308418</td>\n",
       "      <td>0.269116</td>\n",
       "      <td>0.39875</td>\n",
       "      <td>0.35959</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.307006</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>0.276053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total pronouns</th>\n",
       "      <td>0.039823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0119048</td>\n",
       "      <td>0.0222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal pronouns</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First pers singular</th>\n",
       "      <td>0.0575221</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.0555556</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>0.0434783</td>\n",
       "      <td>0.0769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First pers plural</th>\n",
       "      <td>0.0323255</td>\n",
       "      <td>0.00466803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00169132</td>\n",
       "      <td>0.0170671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swear words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00990099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netspeak</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00145391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfluencies</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fillers</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Apple AirPods with Charging Case NutriBullet  \\\n",
       "Total function words                         0.314754    0.361023   \n",
       "Total pronouns                               0.039823         NaN   \n",
       "Personal pronouns                                 NaN         NaN   \n",
       "First pers singular                         0.0575221        0.03   \n",
       "First pers plural                           0.0323255  0.00466803   \n",
       "...                                               ...         ...   \n",
       "Swear words                                       NaN         NaN   \n",
       "Netspeak                                          NaN         NaN   \n",
       "Assent                                            NaN         NaN   \n",
       "Nonfluencies                                      NaN         NaN   \n",
       "Fillers                                           NaN         NaN   \n",
       "\n",
       "                     CLIF BAR - Energy Bars  \\\n",
       "Total function words               0.308418   \n",
       "Total pronouns                          NaN   \n",
       "Personal pronouns                       NaN   \n",
       "First pers singular                     NaN   \n",
       "First pers plural                       NaN   \n",
       "...                                     ...   \n",
       "Swear words                             NaN   \n",
       "Netspeak                                NaN   \n",
       "Assent                                  NaN   \n",
       "Nonfluencies                            NaN   \n",
       "Fillers                                 NaN   \n",
       "\n",
       "                     Charmin Ultra Soft Cushiony Touch Toilet Paper  \\\n",
       "Total function words                                       0.269116   \n",
       "Total pronouns                                                  NaN   \n",
       "Personal pronouns                                               NaN   \n",
       "First pers singular                                             NaN   \n",
       "First pers plural                                               NaN   \n",
       "...                                                             ...   \n",
       "Swear words                                                     NaN   \n",
       "Netspeak                                                        NaN   \n",
       "Assent                                                          NaN   \n",
       "Nonfluencies                                                    NaN   \n",
       "Fillers                                                         NaN   \n",
       "\n",
       "                     Pantene Moisturizing Shampoo and Conditioner  \\\n",
       "Total function words                                      0.39875   \n",
       "Total pronouns                                                NaN   \n",
       "Personal pronouns                                             NaN   \n",
       "First pers singular                                      0.039604   \n",
       "First pers plural                                             NaN   \n",
       "...                                                           ...   \n",
       "Swear words                                            0.00990099   \n",
       "Netspeak                                                      NaN   \n",
       "Assent                                                        NaN   \n",
       "Nonfluencies                                                  NaN   \n",
       "Fillers                                                       NaN   \n",
       "\n",
       "                     Acrylic Paint Set Gatorade Thirst Quencher  \\\n",
       "Total function words           0.35959                 0.368902   \n",
       "Total pronouns                     NaN                0.0119048   \n",
       "Personal pronouns                  NaN                      NaN   \n",
       "First pers singular          0.0555556                 0.047619   \n",
       "First pers plural                  NaN                      NaN   \n",
       "...                                ...                      ...   \n",
       "Swear words                        NaN                      NaN   \n",
       "Netspeak                           NaN                      NaN   \n",
       "Assent                             NaN                      NaN   \n",
       "Nonfluencies                       NaN                      NaN   \n",
       "Fillers                            NaN                      NaN   \n",
       "\n",
       "                     180s Fleece Behind-the-Head Earmuffs  \\\n",
       "Total function words                             0.307006   \n",
       "Total pronouns                                  0.0222222   \n",
       "Personal pronouns                                     NaN   \n",
       "First pers singular                             0.0666667   \n",
       "First pers plural                                     NaN   \n",
       "...                                                   ...   \n",
       "Swear words                                           NaN   \n",
       "Netspeak                                              NaN   \n",
       "Assent                                                NaN   \n",
       "Nonfluencies                                          NaN   \n",
       "Fillers                                               NaN   \n",
       "\n",
       "                     Echo Plus (2nd Gen) with Philips Hue Bulb  \\\n",
       "Total function words                                  0.392547   \n",
       "Total pronouns                                             NaN   \n",
       "Personal pronouns                                          NaN   \n",
       "First pers singular                                  0.0434783   \n",
       "First pers plural                                   0.00169132   \n",
       "...                                                        ...   \n",
       "Swear words                                                NaN   \n",
       "Netspeak                                                   NaN   \n",
       "Assent                                              0.00145391   \n",
       "Nonfluencies                                               NaN   \n",
       "Fillers                                                    NaN   \n",
       "\n",
       "                     adidas Women's Grand Court Sneaker  \n",
       "Total function words                           0.276053  \n",
       "Total pronouns                                      NaN  \n",
       "Personal pronouns                                   NaN  \n",
       "First pers singular                           0.0769231  \n",
       "First pers plural                             0.0170671  \n",
       "...                                                 ...  \n",
       "Swear words                                         NaN  \n",
       "Netspeak                                            NaN  \n",
       "Assent                                              NaN  \n",
       "Nonfluencies                                        NaN  \n",
       "Fillers                                             NaN  \n",
       "\n",
       "[71 rows x 10 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_data_df.to_csv(\"negative_reviews_breakdown.csv\")\n",
    "negative_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
